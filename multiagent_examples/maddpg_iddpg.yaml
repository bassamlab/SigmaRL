seed: 0

env:
  max_steps: 300
  scenario_name: "car_like_robots" # car_like_robots (default: balance)
  scenario:
    n_agents: 9
  device: ??? # These values will be populated dynamically
  vmas_envs: ???

model:
  shared_parameters: True # MADDPG paper does not use shared params because reward function can be different
  centralised_critic: True # MADDPG if True, IDDPG if False

collector:
  frames_per_batch: 60_000 # Frames sampled each sampling iteration
  n_iters: 100  # Number of sampling/training iterations (default 500)
  total_frames: ???

buffer:
  memory_size: ???

loss:
  gamma: 0.9
  tau: 0.005 # For target net

train:
  num_epochs: 45  # optimization steps per batch of data collected
  minibatch_size: 4096 # size of minibatches used in each epoch
  lr: 5e-5
  max_grad_norm: 40.0
  device: ???

eval:
  evaluation_interval: 1
  evaluation_episodes: 10

logger:
  backend:  wandb # Delete to remove logging
